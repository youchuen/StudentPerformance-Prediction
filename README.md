# Student Performance Prediction Pipeline

This repository contains a fully automated end-to-end pipeline to preprocess student performance data, perform exploratory data analysis, select features, train a suite of classification models, and evaluate themâ€”all reproducibly in an isolated Python environment.

---

## ğŸ“‚ Repository Structure
StudentPerformance-Prediction/
â”œâ”€â”€ config.yaml # All your tunable settings: seeds, test split, grids, selected features, target name, bin_cols
â”œâ”€â”€ environment.txt # Pinned package dependencies
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ run_all.sh # Bootstrap venv & run the full pipeline
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ data.csv # Raw input data
â”‚ â””â”€â”€ processed/
â”‚ â”œâ”€â”€ cleaned.csv # Cleaned output from data_preprocessing
â”‚ â””â”€â”€ features.csv # Selected features saved by feature_selection
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ figures/ # All plots (EDA, selectedâ€feature distributions, confusion matrices, ROC curves, etc.)
â”‚ â””â”€â”€ models/ # Fitted model .pkl files & perâ€model CSV reports
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ config.py # Loads constants from config.yaml
â”‚ â”œâ”€â”€ data_preprocessing.py # Cleans & normalizes raw data â†’ cleaned.csv
â”‚ â”œâ”€â”€ eda.py # Generates histograms, boxplots under outputs/figures
â”‚ â”œâ”€â”€ feature_selection.py # Computes feature importances & saves selected_features â†’ features.csv
â”‚ â”œâ”€â”€ modeling.py # Trains LR, RF, XGB variants, saves models + reports + figures
â”‚ â””â”€â”€ evaluation.py # Aggregates all reports into a summary CSV & plots ROC AUC comparison
â”œâ”€â”€ streamlit_app/
â”‚ â”œâ”€â”€app.py # Run streamlit app
â”‚ â”œâ”€â”€generate_streamlit_componenets.py # Generate all required components for Streamlit app from existing models
â””â”€â”€ README.md # (this file)

## ğŸš€ Quick Start

1. **Clone the repo**  
   ```bash
   git clone https://github.com/youchuen/StudentPerformance-Prediction.git
   cd StudentPerformance-Prediction
2. **Run the full pipeline**
    ```bash  
    bash scripts/run_all.sh

    This will:
        a. Create (or reuse) a Python 3 virtual environment in ./.venv/

        b. Install everything in requirements.txt

        c. Execute each step in order:

        d. Data preprocessing (src.data_preprocessing)

        e. Exploratory Data Analysis (src.eda)

        f. Feature selection (src.feature_selection)

        g. Model training (src.modeling --run-all)

        h. Evaluation & summary (src.evaluation)

        i. Run pre-requisite for streamlit app and lauch streamlit app on lcoal host
3. **Inspect your results**
    ```bash  
    a. Cleaned & featureâ€engineered data:
        data/processed/cleaned.csv, data/processed/features.csv

    b. Plots:
        outputs/figures/

    c. Models & perâ€model reports:
        outputs/models/

    d. Combined summary & bestâ€model selection in outputs (outputs/summary/, outputs/figures/roc_auc_comparison.png)

